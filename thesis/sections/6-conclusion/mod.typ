#import "../../lib/mod.typ": *

// + How can pixel-subset-based deep learning approaches be optimized to improve accuracy and efficiency in path planning for autonomous vehicles at intersections? How do convolution-based and transformer-based models compare in this context?
// + Is it possible to design a loss function that effectively captures the similarity between generated and desired paths for autonomous vehicles without forcing exact matches?
// + Is it possible to create a dataset that allows for the training of a model, such that the data is not too stringent to a singular path?

= Conclusion & Future Work #checked <c7:conclusion>

This thesis addressed the significant challenge autonomous vehicles face in navigating intersections by proposing a system to pre-plan traversal paths using deep learning models trained on satellite imagery. Three focused research questions, #RQn(1) to #RQn(3), were posed around model efficiency, loss-function design and dataset tolerance, all aimed at generating robust, topology-correct paths from overhead imagery.

This thesis delivered three principal outcomes. First, a two-split intersection dataset with per-pixel labels, cold map overlays and an explicit train/test separation at the folder level was created. Second, different loss functions, including standard Cross-Entropy and topological approaches like the novel cold map loss and a Persistent Homology-based continuity loss, were developed, implemented, and tested to guide path generation. Finally, four architectures—DeepLabV3+, U-Net, ViT, and Swin—were compared, revealing that while DeepLab achieved the best mean IoU (0.45), U-Net was by far the fastest at inference ($approx 4"ms"$ on the test platform).

Taken together, the experiments answer the research questions as follows. #RQn(1): Optimization of the four models was attempted with various combinations of loss functions. Introducing topology-aware loss functions did improve the visual performance of the convolution-based models, while the transformer-based models did not. Overall, the convolutional models did perform the greatest, both in terms of accuracy and efficiency. Neither sets of models excelled at the solving the problem, likely due to the limited size and diversity of the dataset. #RQn(2): The cold map loss introduced structural prior knowledge into the training process. The distance-based penalty applied to generated pixels, allowed for some leeway in how the models generated their predictions. Neither of the topology-aware loss functions were able to improve mIoU for any of the models. #RQn(3): The developed dataset with wider path annotations and cold maps aimed to offer flexibility. However, despite extensive data augmentation, significant overfitting was a persistent challenge across all models. Key limitations therefore lie in data diversity, GPU memory ceilings that hindered transformer capacity, and the CPU-bound nature of topology-loss calculations.

Future work should prioritize the creation of a significantly larger, more diverse, and potentially synthetically augmented dataset to mitigate overfitting and improve model generalization. Further refinement of loss functions, including exploring alternatives like Focal or Dice Loss or different formulations for the cold cap and continuity losses, is warranted. Finally, addressing practical implementation aspects, such as robust image rotation based on GPS data and efficient post-processing techniques for path refinement, will be essential steps toward realizing the potential of this pre-planning approach for enhancing AV navigation capabilities.
