{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import IntersectionDataset\n",
    "reload(IntersectionDataset)\n",
    "from IntersectionDataset import IntersectionDatasetClasses, custom_collate_fn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import multiprocessing\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset/train\"\n",
    "img_transform = ToTensor()\n",
    "path_transform = ToTensor()\n",
    "dataset = IntersectionDatasetClasses(root_dir=dataset_dir,\n",
    "                              transform=img_transform,\n",
    "                              path_transform=path_transform)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find num_workers\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "b = 1\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=b, \n",
    "                        shuffle=True, \n",
    "                        num_workers=num_workers,\n",
    "                        collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch[\"satellite\"].shape)\n",
    "    print(batch[\"class_labels\"].shape)\n",
    "    print(batch[\"paths\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "cols, rows = 4, 2\n",
    "ii = 0\n",
    "c = 0\n",
    "\n",
    "for batch in dataloader:\n",
    "    satellite = batch[\"satellite\"]\n",
    "    path_line = batch[\"path_line\"]\n",
    "    ee_data = batch[\"ee_data\"]\n",
    "    cold_map = batch[\"cold_map\"]\n",
    "    \n",
    "    greyscale_image = path_line[0].permute(1, 2, 0).numpy()\n",
    "    \n",
    "    satellite_image = satellite[0].permute(1, 2, 0).numpy()\n",
    "    \n",
    "    fig.add_subplot(rows, cols, ii + 1)\n",
    "    \n",
    "    #remove tensor from ee_data\n",
    "    ee_e_x = ee_data['entry']['x'].detach().numpy().tolist()\n",
    "    ee_e_y = ee_data['entry']['y'].detach().numpy().tolist()\n",
    "    ee_x_x = ee_data['exit']['x'].detach().numpy().tolist()\n",
    "    ee_x_y = ee_data['exit']['y'].detach().numpy().tolist()\n",
    "    ee_data['entry']['x'] = ee_e_x\n",
    "    ee_data['entry']['y'] = ee_e_y\n",
    "    ee_data['exit']['x'] = ee_x_x\n",
    "    ee_data['exit']['y'] = ee_x_y\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w', alpha=0.0, linewidth=0.0, label=f\"Entry: {ee_data['entry']}\"),\n",
    "                       Line2D([0], [0], marker='o', color='w', alpha=0.0, linewidth=0.0, label=f\"Exit: {ee_data['exit']}\"),\n",
    "                       #Line2D([0], [0], marker='o', color='w', alpha=0.0, linewidth=0.0, label=f\"Cold Map Loss: {L_cmap:.2f}\"),\n",
    "                       #Line2D([0], [0], marker='o', color='w', alpha=0.0, linewidth=0.0, label=f\"BCE Loss: {L_bce:.2f}\")\n",
    "                       ]\n",
    "    \n",
    "    plt.legend(handles=legend_elements, loc='upper right')\n",
    "    plt.imshow(greyscale_image, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    ii += 1   \n",
    "     \n",
    "    fig.add_subplot(rows, cols, ii + 1)\n",
    "    plt.imshow(satellite_image)\n",
    "    plt.axis(\"off\")\n",
    "    ii += 1\n",
    "    \n",
    "\n",
    "    if ii >= cols * rows:\n",
    "        break\n",
    "\n",
    "print(dataset.__len__())\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"img/loader/loader_2.png\", transparent=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "cols, rows = 4, 2\n",
    "ii = 0\n",
    "c = 0\n",
    "\n",
    "for batch in dataloader:\n",
    "    satellite = batch[\"satellite\"]\n",
    "    class_labels = batch[\"class_labels\"]\n",
    "    ee_data = [batch[\"paths\"][0][1][\"ee_data\"] for i in range(len(batch[\"paths\"][0]))]\n",
    "    #print(ee_data)\n",
    "    \n",
    "    greyscale_image = class_labels[0].permute(1, 2, 0).numpy()\n",
    "    \n",
    "    satellite_image = satellite[0].permute(1, 2, 0).numpy()\n",
    "    \n",
    "    fig.add_subplot(rows, cols, ii + 1)\n",
    "    \n",
    "    #remove tensor from ee_data\n",
    "    plt.imshow(greyscale_image, cmap='inferno')\n",
    "    plt.colorbar()\n",
    "    plt.axis(\"off\")\n",
    "    ii += 1   \n",
    "     \n",
    "    fig.add_subplot(rows, cols, ii + 1)\n",
    "    plt.imshow(satellite_image)\n",
    "    plt.axis(\"off\")\n",
    "    ii += 1\n",
    "    \n",
    "\n",
    "    if ii >= cols * rows:\n",
    "        break\n",
    "\n",
    "print(dataset.__len__())\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"img/loader/loader_2.png\", transparent=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=b, shuffle=True, num_workers=num_workers, collate_fn=custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=b, shuffle=True, num_workers=num_workers, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "import importlib\n",
    "from dataset import dataset_lib as dl\n",
    "from loss import loss_lib as ll\n",
    "importlib.reload(ll)\n",
    "importlib.reload(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lc = ll.CmapLoss(1/1000)\n",
    "\n",
    "\n",
    "comp_path = \"./img/comp2.png\"\n",
    "\n",
    "cmap_gt = p[\"cold_map\"]\n",
    "\n",
    "path = cv2.imread(comp_path, cv2.IMREAD_GRAYSCALE)\n",
    "_, binary = cv2.threshold(path, 1, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "cmap2 = torch.from_numpy(cmap_gt).float()\n",
    "cmap_f = torch.flatten(cmap2)\n",
    "\n",
    "path_np = np.array(path)\n",
    "path_t = torch.from_numpy(path_np).float().requires_grad_(True)\n",
    "path_f = torch.flatten(path_t)\n",
    "\n",
    "\n",
    "L_cmap = Lc(cmap_f, path_f)\n",
    "L_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lb = ll.BCELoss()\n",
    "\n",
    "ground_truth = p[\"path_line\"].detach().numpy()[0]\n",
    "\n",
    "prediction = cv2.imread(comp_path, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "\n",
    "gt_tensor = torch.from_numpy(ground_truth).float()\n",
    "p_tensor = torch.from_numpy(prediction).float().requires_grad_(True)\n",
    "\n",
    "L_bce = Lb(gt_tensor, p_tensor)\n",
    "L_bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "cols, rows = 4, b\n",
    "ii = 0\n",
    "c = 0\n",
    "\n",
    "Lc = ll.CmapLoss(1/1000)\n",
    "Lb = ll.BCELoss()\n",
    "\n",
    "\n",
    "comp_path = \"./img/comp2.png\"\n",
    "\n",
    "path_np = np.array(comp_path)\n",
    "path = cv2.imread(comp_path, cv2.IMREAD_GRAYSCALE)\n",
    "path_t = torch.from_numpy(path).float().requires_grad_(True)\n",
    "path_f = torch.flatten(path_t)\n",
    "\n",
    "p_tensor = cv2.imread(comp_path, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "p_tensor = torch.from_numpy(p_tensor).float().requires_grad_(True)\n",
    "print(p_tensor.shape)\n",
    "\n",
    "l = 0\n",
    "for batch in dataloader:\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    cols, rows = 4, b\n",
    "    ii = 0\n",
    "    c = 0\n",
    "    \n",
    "    # The batch is a dictionary with keys \"satellite\" and \"paths\"\n",
    "    satellite_batch = batch[\"satellite\"]\n",
    "    paths_batch = batch[\"paths\"]\n",
    "    print(\"Satellite batch type:\", type(satellite_batch))\n",
    "    print(\"Number of intersections in batch:\", len(satellite_batch))\n",
    "    print(\"Number of paths in batch:\", len(paths_batch))\n",
    "    #print(\"Paths info for first intersection in batch:\", paths_batch[0])\n",
    "    \n",
    "    for j in range(len(satellite_batch)):\n",
    "        if c == 2:\n",
    "            ii += 1\n",
    "            \n",
    "        fig.add_subplot(rows, cols, ii + 1)\n",
    "        plt.imshow(satellite_batch[j].permute(1, 2, 0))\n",
    "        plt.axis(\"off\")\n",
    "        ii += 1\n",
    "        \n",
    "        c = 0\n",
    "        for k, p in enumerate(paths_batch[j]):\n",
    "            c += 1\n",
    "            line = p[\"path_line\"]\n",
    "            # cold map loss\n",
    "            cmap_gt = p[\"cold_map\"]\n",
    "            cmap2 = torch.from_numpy(cmap_gt).float()\n",
    "            cmap_f = torch.flatten(cmap2)\n",
    "            L_cmap = Lc(cmap_f, path_f)\n",
    "            \n",
    "            # bce loss\n",
    "            gt_tensor = p[\"path_line\"].detach().numpy()[0]\n",
    "            gt_tensor = torch.from_numpy(gt_tensor).float()\n",
    "            L_bce = Lb(gt_tensor, p_tensor)\n",
    "            \n",
    "            ee = p[\"ee_data\"]\n",
    "            legend_elements = [Line2D([0], [0], marker='o', color='w', alpha=0.0, linewidth=0.0, label=f\"Entry: {ee['entry']}\"),\n",
    "                               Line2D([0], [0], marker='o', color='w', alpha=0.0, linewidth=0.0, label=f\"Exit: {ee['exit']}\"),\n",
    "                               #Line2D([0], [0], marker='o', color='w', alpha=0.0, linewidth=0.0, label=f\"Cold Map Loss: {L_cmap:.2f}\"),\n",
    "                               #Line2D([0], [0], marker='o', color='w', alpha=0.0, linewidth=0.0, label=f\"BCE Loss: {L_bce:.2f}\")\n",
    "                               ]\n",
    "            \n",
    "            line = line.detach().numpy()\n",
    "            grayscale_image = line[0]  # Assuming the first channel represents the grayscale image\n",
    "            fig.add_subplot(rows, cols, ii + 1)\n",
    "            plt.legend(handles=legend_elements, loc='upper right')\n",
    "            #plt.title(f\"cold map loss: {L_cmap:.2f}, bce loss: {L_bce:.2f}\")\n",
    "            plt.imshow(grayscale_image, cmap='gray')\n",
    "            plt.axis(\"off\")\n",
    "            ii += 1\n",
    "            \n",
    "        fig.tight_layout()\n",
    "        fig.savefig(f\"./img/loader/loader_{l}.png\", transparent=True)\n",
    "\n",
    "    \n",
    "    if l == 0:\n",
    "        break\n",
    "\n",
    "    l += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".msc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
