import cv2
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import gudhi as gd

class CmapLoss(nn.Module):
    def __init__(self, weight: float = 1.0):
        super(CmapLoss, self).__init__()
        self.weight = weight
        
    def forward(self, cmap_gt: torch.Tensor, path_pred: torch.Tensor):
        loss = cmap_loss_torch(cmap_gt, path_pred)
        return self.weight * loss

def cmap_loss(cmap_gt: np.ndarray, path_pred: np.ndarray) -> torch.Tensor:
    """
    Compute the dot product loss between a ground truth cold map and a predicted path.
    Args:
        cmap_gt (np.ndarray): Ground truth cold map as a NumPy array.
        path_pred (np.ndarray): Predicted path as a NumPy array.
    Returns:
        torch.Tensor: The computed loss as a torch.Tensor.
    """
    cmap = torch.from_numpy(cmap_gt).float()
    cmap_f = torch.flatten(cmap)
    
    path_np = np.array(path_pred)
    path_t = torch.from_numpy(path_np).float()
    path_f = torch.flatten(path_t)
    
    return torch.dot(cmap_f, path_f)

def cmap_loss_torch(cmap_gt: torch.Tensor, path_pred: torch.Tensor):
    """
    Compute the dot product loss between a ground truth cold map and a predicted path.
    Args:
        cmap_gt (torch.Tensor): Ground truth cold map as a torch.Tensor.
        path_pred (torch.Tensor): Predicted path as a torch.Tensor.
    Returns:
        torch.Tensor: The computed loss as a torch.Tensor.
    """
    cmap_f = torch.flatten(cmap_gt)
    path_f = torch.flatten(path_pred)
    
    loss = torch.dot(cmap_f, path_f)
    
    return loss

class BCELoss(nn.Module):
    """
    Binary Cross-Entropy Loss with an optional weighting factor.
    Args:
        weight (float, optional): A weighting factor to scale the loss. Default is 1.0.
        
    Methods:
    
        forward(path_gt: torch.Tensor, path_pred: torch.Tensor, reduction: str = 'mean') -> torch.Tensor:
            Computes the weighted binary cross-entropy loss between the ground truth and the predictions.
            Args:
                path_gt (torch.Tensor): Ground truth tensor.
                path_pred (torch.Tensor): Predicted tensor.
                reduction (str, optional): Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. Default is 'mean'.
            Returns:
                torch.Tensor: The computed weighted binary cross-entropy loss.
    """
    def __init__(self, weight: float = 1.0):
        super(BCELoss, self).__init__()
        self.weight = weight
        
    def forward(self, path_gt: torch.Tensor, path_pred: torch.Tensor, reduction: str = 'mean'):
        loss = bce_loss_torch(path_gt, path_pred, reduction)
        return self.weight * loss

def bce_loss(path_gt: str, path_pred: str, reduction: str = "mean") -> float:
    """
    Calculate Binary Cross Entropy (BCE) loss between two black and white images using OpenCV.
    
    Args:
        ground_truth_path (str): Path to the ground truth image containing a path (black and white).
        prediction_path (str): Path to the prediction image generated by a model (black and white).
        reduction (str): Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. Default: 'mean'.
        
    Returns:
        float: The BCE loss value between the two images.
    """
    ground_truth_img = cv2.imread(path_gt, cv2.IMREAD_GRAYSCALE)
    prediction_img = cv2.imread(path_pred, cv2.IMREAD_GRAYSCALE)
    
    if ground_truth_img is None:
        raise ValueError(f"Failed to load ground truth image from {path_gt}")
    if prediction_img is None:
        raise ValueError(f"Failed to load prediction image from {path_pred}")
    
    if ground_truth_img.shape != prediction_img.shape:
        raise ValueError(f"Image dimensions do not match: {ground_truth_img.shape} vs {prediction_img.shape}")
    
    # Normalize to [0, 1] since uint8
    ground_truth = ground_truth_img / 255.0
    prediction = prediction_img / 255.0
    
    # Convert numpy arrays to PyTorch tensors
    ground_truth_tensor = torch.from_numpy(ground_truth).float()
    prediction_tensor = torch.from_numpy(prediction).float()
       
    criterion = torch.nn.BCELoss(reduction=reduction)
    
    bce_loss = criterion(prediction_tensor, ground_truth_tensor)
    
    return bce_loss

def bce_loss_torch(path_gt, path_pred, reduction) -> torch.Tensor:
    """
    Calculate Binary Cross Entropy (BCE) loss between two black and white images using PyTorch.
    
    Args:
        ground_truth (torch.Tensor): Ground truth image containing a path (black and white).
        prediction (torch.Tensor): Prediction image generated by a model (black and white).
        reduction (str): Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. Default: 'mean'.
        
    Returns:
        torch.Tensor: The BCE loss value between the two images.
    """
    if path_gt.shape != path_pred.shape:
        raise ValueError(f"Image dimensions do not match: {path_gt.shape} vs {path_pred.shape}")
    
    # Initialize BCE loss function with specified reduction
    criterion = torch.nn.BCELoss(reduction=reduction)
    
    # Calculate BCE loss
    bce_loss = criterion(path_pred, path_gt)
    
    return bce_loss

def topology_loss(path_pred):
    pass

class TopoLoss(nn.Module):
    def __init__(self, weight: float = 1.0):
        super(TopoLoss, self).__init__()
        self.weight = weight
        
    def forward(self, path_pred: torch.Tensor):
        loss = topology_loss(path_pred)
        return self.weight * loss
    

class PersistentHomologyLossFunction(torch.autograd.Function):

    @staticmethod # <- required by docs
    def forward(ctx, input_tensor, target_betti, threshold):
        array = input_tensor.detach().cpu().numpy()
        array_inv = 1.0 - array
        cc = gd.CubicalComplex(top_dimensional_cells=array_inv)
        
        # Compute Betti numbers (counts) for each dimension, 
        # considering only features with death > threshold (or infinite death)
        computed_betti = {}
        for dim, (birth, death) in cc.persistence():
            if death == float('inf') or death > threshold:
                computed_betti.setdefault(dim, 0)
                computed_betti[dim] += 1

        # Save these for the backward pass.
        ctx.computed_betti = computed_betti
        ctx.target_betti = target_betti
        ctx.input_shape = input_tensor.shape

        # Compute the Wasserstein (L2) loss between Betti number vectors.
        # Here we assume that the target and computed diagrams can be represented as vectors.
        loss_sq = 0.0
        for dim, target in target_betti.items():
            comp = computed_betti.get(dim, 0)
            diff = comp - target
            loss_sq += diff * diff
        loss_value = np.sqrt(loss_sq)

        # Save the computed loss and per-dimension differences for backward.
        ctx.loss_value = loss_value
        ctx.diff_dict = {dim: computed_betti.get(dim, 0) - target for dim, target in target_betti.items()}

        return torch.tensor(loss_value, dtype=input_tensor.dtype, device=input_tensor.device)

    @staticmethod
    def backward(ctx, grad_output):

        total_diff = 0.0
        for diff in ctx.diff_dict.values():
            total_diff += diff

        # Avoid division by zero:
        L_val = ctx.loss_value if ctx.loss_value > 1e-8 else 1e-8

        grad_scalar = total_diff / L_val

        # Spread the gradient uniformly over the input.
        grad_input = grad_output * grad_scalar * torch.ones(ctx.input_shape, device=grad_output.device)

        return grad_input, None, None

class PersistentHomologyLoss(nn.Module):
    def __init__(self, target_betti, threshold=0.5):
        super(PersistentHomologyLoss, self).__init__()
        self.target_betti = target_betti
        self.threshold = threshold

    def forward(self, input_tensor):
        return PersistentHomologyLossFunction.apply(input_tensor, self.target_betti, self.threshold)
    

class EndpointsLossFunction(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input_tensor, target_ee, alpha = 70.0, threshold = 0.85):
        """
        Compute a differentiable measure of endpoints and the squared error loss.
        input_tensor: a 2D tensor (greyscale image) with continuous activations.
        target_ee: the target number of endpoints (usually 2).
        """
        input_tensor = input_tensor / 255.0
        input_tensor = torch.sigmoid(alpha * ((input_tensor) - threshold))
        
        # [1, 1, H, W] required for conv2d
        p = input_tensor.unsqueeze(0).unsqueeze(0)
        
        # Create and unsqueeze the kernel
        kernel = torch.tensor([[1, 1, 1], 
                               [1, 0, 1], 
                               [1, 1, 1]], 
                              dtype=torch.float32).unsqueeze(0).unsqueeze(0)
        
        # Convolve the image with the kernel and remove the batch and channel dimensions
        neighbour_sum = F.conv2d(p, kernel, padding=1).squeeze(0).squeeze(0)
        
        # Use smooth indicator function to approximate the number of endpoints
        sigma = 0.1
        desired_endpoints = 1
        indicator = torch.exp(-((neighbour_sum - desired_endpoints) ** 2) / (2 * sigma ** 2))
        
        # Compute soft endpoint map
        endpoints_map = input_tensor * indicator
        measured_endpoints = torch.sum(endpoints_map)
        
        # Compute the squared error loss
        loss_value = (measured_endpoints - target_ee) ** 2
        
        # save for backward pass
        ctx.save_for_backward(input_tensor, neighbour_sum, indicator, kernel)
        ctx.sigma = sigma
        ctx.alpha = alpha
        ctx.threshold = threshold
        ctx.target_ee = target_ee
        
        return loss_value
    
    @staticmethod
    def backward(ctx, grad_output):
        """
        Compute the gradient of the loss with respect to the input_tensor.
        The loss is:
            L = (E - T)^2,
        where E = sum_{i,j} p[i,j] * exp(-((NS[i,j]-1)**2)/(2*sigma^2))
        and NS is the neighbour sum (via convolution).
        """
        input_tensor, neighbour_sum, indicator, kernel = ctx.saved_tensors
        alpha = ctx.alpha
        threshold = ctx.threshold
        sigma = ctx.sigma
        target_ee = ctx.target_ee
        
        # recompute the number of endpoints
        E = (input_tensor * indicator).sum()
        
        dL_dE = 2 * (E - target_ee)
        
        # Compute derivative
        # direct d/dp (p * indicator) = indicator
        grad_direct = indicator
        
        # indirect
        factor = -(neighbour_sum - 1) / (sigma ** 2)
        
        conv_input = (input_tensor * indicator * factor).unsqueeze(0).unsqueeze(0)
        grad_indirect = F.conv2d(conv_input, kernel, padding=1).squeeze(0).squeeze(0)
        
        grad_total = grad_direct + grad_indirect
        
        soft_thresholded = torch.sigmoid(alpha * (input_tensor - threshold))
        sigmoid_deriv = (alpha / 255.0) * soft_thresholded * (1 - soft_thresholded)
        
        grad_input = grad_output * dL_dE * grad_total * sigmoid_deriv
        
        return grad_input, None
    
class EndpointsLoss(nn.Module):
    def __init__(self, target_ee, alpha = 50.0, threshold = 0.8):
        super(EndpointsLoss, self).__init__()
        self.target_ee = target_ee
        self.alpha = alpha
        self.threshold = threshold

    def forward(self, input_tensor):
        return EndpointsLossFunction.apply(input_tensor, self.target_ee, self.alpha, self.threshold)
        
        