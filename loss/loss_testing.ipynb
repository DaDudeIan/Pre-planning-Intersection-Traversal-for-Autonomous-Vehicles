{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "import importlib, loss_lib as ll\n",
    "from dataset import dataset_lib as dl\n",
    "importlib.reload(ll)\n",
    "importlib.reload(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Testing Notebook\n",
    "## Coldmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gt_path = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "gt_cmap = \"./intersection_001/paths/path_1/cold_map.png\"\n",
    "test_path = \"./comps/comp1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = dl.get_nearest_coords(gt_path)\n",
    "cmap = dl.coords_to_coldmap(coords)\n",
    "cmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "_, binary = cv2.threshold(path, 1, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "loss = ll.cmap_loss(cmap, binary)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "comps = [\"./comps/comp1.png\", \"./comps/comp2.png\", \"./comps/comp3.png\", \"./comps/comp7.png\", \"./comps/comp8.png\"] + [gt_path]\n",
    "\n",
    "paths = [cv2.imread(c, cv2.IMREAD_GRAYSCALE) for c in comps]\n",
    "\n",
    "_, binaries = zip(*[cv2.threshold(p, 1, 1, cv2.THRESH_BINARY) for p in paths])\n",
    "\n",
    "losses = [ll.cmap_loss(cmap, b) for b in binaries]\n",
    "\n",
    "for i, (p, b, l) in enumerate(zip(paths, binaries, losses)):\n",
    "    axs[i // 3, i % 3].imshow(cmap, cmap=\"inferno\")\n",
    "    axs[i // 3, i % 3].imshow(p, cmap=\"gray\", alpha=0.5)\n",
    "    axs[i // 3, i % 3].set_title(f\"Loss: {l:.2f}\", fontsize=18)\n",
    "    axs[i // 3, i % 3].axis(\"off\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.08)\n",
    "\n",
    "#fig.savefig(\"cmap_loss_comparison3.png\", transparent=True)\n",
    "#plt.savefig(\"loss_comparison.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "gt_cmap = \"./intersection_001/paths/path_1/cold_map.png\"\n",
    "test_path = \"./comps/comp8.png\"\n",
    "\n",
    "l = ll.CmapLoss(1/1000)\n",
    "\n",
    "cmap_gt = cv2.imread(gt_cmap, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "path = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "_, binary = cv2.threshold(path, 1, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "cmap2 = torch.from_numpy(cmap).float().requires_grad_(True)\n",
    "cmap_f = torch.flatten(cmap2)\n",
    "\n",
    "path_np = np.array(path)\n",
    "path_t = torch.from_numpy(path_np).float().requires_grad_(True)\n",
    "path_f = torch.flatten(path_t)\n",
    "\n",
    "loss = l(cmap_f, path_f)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Example usage\n",
    "    ground_truth_path = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "    prediction_path = \"./comps/comp5.png\"\n",
    "    \n",
    "    try:\n",
    "        loss = ll.bce_loss(ground_truth_path, prediction_path)\n",
    "        print(f\"BCE Loss: {loss:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "comps = [\"./comps/comp2.png\", \"./comps/comp3.png\", \"./comps/comp4.png\", \"./comps/comp5.png\", \"./comps/comp6.png\", \"./comps/comp7.png\", \"./comps/comp8.png\"] + [gt_path]\n",
    "\n",
    "paths = [cv2.imread(c, cv2.IMREAD_GRAYSCALE) for c in comps]\n",
    "\n",
    "_, binaries = zip(*[cv2.threshold(p, 1, 1, cv2.THRESH_BINARY) for p in paths])\n",
    "\n",
    "#losses = [ll.cmap_loss(cmap, b) for b in binaries]\n",
    "losses = [ll.bce_loss(gt_path, b, \"mean\") for b in comps]\n",
    "\n",
    "names = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n",
    "\n",
    "for i, (p, b, l, n) in enumerate(zip(paths, binaries, losses, names)):\n",
    "    t = paths[-1] + p\n",
    "    t = cv2.cvtColor(t, cv2.COLOR_GRAY2BGR)\n",
    "    axs[i // 4, i % 4].imshow(paths[-1], cmap=\"inferno\")\n",
    "    axs[i // 4, i % 4].imshow(p, cmap=\"gray\", alpha=0.5)\n",
    "    #axs[i // 4, i % 4].imshow(t, cmap=\"gray\", alpha=1)\n",
    "    \n",
    "    axs[i // 4, i % 4].set_title(f\"({n}) Loss: {l:.2f}\", fontsize=18)\n",
    "    axs[i // 4, i % 4].axis(\"off\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.08)\n",
    "\n",
    "#fig.savefig(\"cmap_loss_comparison4.png\", transparent=True)\n",
    "#plt.savefig(\"loss_comparison.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gt_path = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "gt_cmap = \"./intersection_001/paths/path_1/cold_map.png\"\n",
    "test_path = \"./comps/comp1.png\"\n",
    "\n",
    "ground_truth_img = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "prediction_img = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "ground_truth = ground_truth_img / 255.0\n",
    "prediction = prediction_img / 255.0\n",
    "\n",
    "gt_tensor = torch.from_numpy(ground_truth).float()\n",
    "p_tensor = torch.from_numpy(prediction).float()\n",
    "\n",
    "print(f\"{gt_tensor.shape=}, {p_tensor.shape=}\")\n",
    "\n",
    "gt_tensor_u1 = gt_tensor.unsqueeze(0)\n",
    "p_tensor_u1 = p_tensor.unsqueeze(0)\n",
    "\n",
    "print(f\"{gt_tensor_u1.shape=}, {p_tensor_u1.shape=}\")\n",
    "\n",
    "gt_tensor_u2 = gt_tensor_u1.unsqueeze(0)\n",
    "p_tensor_u2 = p_tensor_u1.unsqueeze(0)\n",
    "\n",
    "print(f\"{gt_tensor_u2.shape=}, {p_tensor_u2.shape=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.nn.BCELoss()\n",
    "\n",
    "l0 = l(gt_tensor, p_tensor)\n",
    "l1 = l(gt_tensor_u1, p_tensor_u1)\n",
    "l2 = l(gt_tensor_u2, p_tensor_u2)\n",
    "\n",
    "print(f\"{l0=}, {l1=}, {l2=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topology (old)\n",
    "*Finally, the last part of the loss function will deal with the actual topology of the predicted path. It will heavily penalize breaks in the path, branches in paths, and other topological errors, such as not reaching connecting the entry and exit.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gudhi as gd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def load_image_as_tensor(image_path):\n",
    "    \"\"\"\n",
    "    Loads an image from disk, converts it to grayscale, normalizes to [0, 1],\n",
    "    and returns it as a torch.Tensor.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert('L')  # convert to grayscale\n",
    "    image_np = np.array(image, dtype=np.float32)\n",
    "    # Normalize to [0, 1] if the image is in [0, 255]\n",
    "    image_np = image_np / 255.0\n",
    "    return torch.tensor(image_np, dtype=torch.float32)\n",
    "\n",
    "def get_persistence_diagram(image_tensor, homology_dim=0):\n",
    "    \"\"\"\n",
    "    Compute the persistence diagram for a 2D image using a cubical complex.\n",
    "    \n",
    "    Args:\n",
    "        image_tensor (torch.Tensor): a 2D tensor (H x W) representing the image.\n",
    "        homology_dim (int): homology dimension to extract (0 for connected components, 1 for loops, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        diag (np.ndarray): an array of [birth, death] pairs for the chosen homology,\n",
    "                           with infinite intervals removed.\n",
    "    \"\"\"\n",
    "    # Convert the PyTorch tensor to a numpy array.\n",
    "    img = image_tensor.cpu().detach().numpy()\n",
    "    \n",
    "    img_inv = 1.0 - img\n",
    "    \n",
    "    # Create a cubical complex from the inverted image.\n",
    "    cc = gd.CubicalComplex(top_dimensional_cells=img_inv)\n",
    "    cc.persistence()\n",
    "    \n",
    "    # Extract the persistence intervals for the chosen homology dimension.\n",
    "    diag = np.array(cc.persistence_intervals_in_dimension(homology_dim))\n",
    "    # Remove any intervals with infinite values to avoid NaNs.\n",
    "    if diag.size > 0:\n",
    "        diag = diag[np.isfinite(diag).all(axis=1)]\n",
    "    return diag\n",
    "\n",
    "def diagram_distance(pd1, pd2):\n",
    "    \"\"\"\n",
    "    Compute a simple distance between two persistence diagrams.\n",
    "    (For each point in pd1, we take the minimal Euclidean distance to any point in pd2, and then sum these.)\n",
    "    \n",
    "    Args:\n",
    "        pd1 (np.ndarray): array of [birth, death] pairs (shape: N x 2)\n",
    "        pd2 (np.ndarray): array of [birth, death] pairs (shape: M x 2)\n",
    "    \n",
    "    Returns:\n",
    "        distance (float): a scalar distance between the two diagrams.\n",
    "    \"\"\"\n",
    "    # If either diagram is empty, we can define the distance as zero.\n",
    "    if len(pd1) == 0 or len(pd2) == 0:\n",
    "        return 0.0\n",
    "    distance = 0.0\n",
    "    for point in pd1:\n",
    "        dists = np.linalg.norm(pd2 - point, axis=1)\n",
    "        distance += np.min(dists)\n",
    "    return distance\n",
    "\n",
    "def topological_loss(pred, gt, homology_dim=0):\n",
    "    \"\"\"\n",
    "    Compute a topological loss as the distance between the persistence diagrams of\n",
    "    the predicted likelihood map and the ground truth binary path.\n",
    "    \n",
    "    Args:\n",
    "        pred (torch.Tensor): predicted likelihood map (H x W) with values in [0, 1].\n",
    "        gt (torch.Tensor): ground truth binary path (H x W).\n",
    "        homology_dim (int): homology dimension for persistence (0, 1, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        loss (torch.Tensor): a scalar loss.\n",
    "    \"\"\"\n",
    "    # Compute persistence diagrams for the predicted and ground truth images.\n",
    "    pd_pred = get_persistence_diagram(pred, homology_dim)\n",
    "    pd_gt   = get_persistence_diagram(gt, homology_dim)\n",
    "    \n",
    "    # Compute a simple distance between the diagrams.\n",
    "    loss_value = diagram_distance(pd_pred, pd_gt)\n",
    "    \n",
    "    # Wrap the loss value into a torch tensor.\n",
    "    loss = torch.tensor(loss_value, dtype=torch.float32, requires_grad=True)\n",
    "    return loss\n",
    "\n",
    "def plot_image(image, title):\n",
    "    \"\"\"\n",
    "    Plot a 2D image.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "def plot_persistence_diagram(pd, title):\n",
    "    \"\"\"\n",
    "    Plot a persistence diagram.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    if len(pd) > 0:\n",
    "        plt.scatter(pd[:, 0], pd[:, 1], color='blue', marker='o', label='Persistence Points')\n",
    "        # Plot the diagonal\n",
    "        min_val = min(np.min(pd[:, 0]), np.min(pd[:, 1]))\n",
    "        max_val = max(np.max(pd[:, 0]), np.max(pd[:, 1]))\n",
    "        plt.plot([min_val, max_val], [min_val, max_val], 'k--', label='Diagonal')\n",
    "    plt.xlabel(\"Birth\")\n",
    "    plt.ylabel(\"Death\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# === Main execution ===\n",
    "if __name__ == \"__main__\":\n",
    "    # === Variables for the image file paths ===\n",
    "    input_path_image_path = \"./comps/comp12.png\"\n",
    "    gt_path_image_path    = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "\n",
    "    \n",
    "    # Load images from disk as torch tensors.\n",
    "    pred = load_image_as_tensor(input_path_image_path)\n",
    "    gt   = load_image_as_tensor(gt_path_image_path)\n",
    "    \n",
    "    # Plot the input images.\n",
    "    plot_image(pred.cpu().numpy(), \"Predicted Likelihood Map\")\n",
    "    plot_image(gt.cpu().numpy(), \"Ground Truth Path\")\n",
    "    \n",
    "    # Compute persistence diagrams for both images.\n",
    "    pd_pred = get_persistence_diagram(pred, homology_dim=0)\n",
    "    pd_gt = get_persistence_diagram(gt, homology_dim=0)\n",
    "    \n",
    "    # Plot the persistence diagrams.\n",
    "    plot_persistence_diagram(pd_pred, \"Persistence Diagram: Predicted\")\n",
    "    plot_persistence_diagram(pd_gt, \"Persistence Diagram: Ground Truth\")\n",
    "    \n",
    "    a = np.concatenate([pd_pred, pd_gt])\n",
    "    \n",
    "    plot_persistence_diagram(a, \"Persistence Diagram: Combined\")\n",
    "    \n",
    "    # Calculate the topological loss.\n",
    "    loss = topological_loss(pred, gt, homology_dim=0)\n",
    "    print(\"Topological Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from topoloss import TopoLoss, LaplacianPyramid\n",
    "\n",
    "model = models.resnet34(weights = \"DEFAULT\")\n",
    "\n",
    "topo_loss = TopoLoss(\n",
    "    losses = [\n",
    "        LaplacianPyramid.from_layer(\n",
    "            model=model,\n",
    "            layer = model.fc, ## layer to apply topoloss on\n",
    "            factor_h=8.0,\n",
    "            factor_w=8.0,\n",
    "            scale = 1.0  ## strength, equivalent to \"tau\" in the paper\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "t_loss = topo_loss.compute(model=model) ## add this to your training loss during training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gt_path = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "gt_cmap = \"./intersection_001/paths/path_1/cold_map.png\"\n",
    "test_path = \"./comps/comp1.png\"\n",
    "\n",
    "ground_truth_img = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "prediction_img = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "ground_truth = ground_truth_img / 255.0\n",
    "prediction = prediction_img / 255.0\n",
    "\n",
    "gt_tensor = torch.from_numpy(ground_truth).float()\n",
    "p_tensor = torch.from_numpy(prediction).float()\n",
    "\n",
    "bce_loss = ll.bce_loss_torch(gt_tensor, p_tensor)\n",
    "print(f\"BCE Loss: {bce_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = bce_loss + t_loss\n",
    "print(f\"Total Loss: {total_loss:.6f}\")\n",
    "\n",
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define your optimizer with the model parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Set a weighting factor for the topo loss if needed\n",
    "lambda_topo = 0.1\n",
    "\n",
    "# Training loop\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()  # zero the gradients\n",
    "    \n",
    "    # forward pass\n",
    "    \n",
    "\n",
    "    # Compute the losses\n",
    "    t_loss = topo_loss.compute(model=model)\n",
    "    bce_loss = ll.bce_loss_torch(gt_tensor, p_tensor)\n",
    "\n",
    "    # Combine the losses (apply lambda if needed)\n",
    "    total_loss = bce_loss + lambda_topo * t_loss\n",
    "\n",
    "    # Backpropagation and optimizer step\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print losses every 100 iterations (or adjust the frequency)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}: BCE loss = {bce_loss.item():.4f}, Topo loss = {t_loss.item():.4f}, Total loss = {total_loss.item():.4f}\")\n",
    "        \n",
    "model.fc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topology Loss\n",
    "## Continuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_path = \"./comps/comp9.png\"\n",
    "    prediction = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    p_tensor = torch.from_numpy(prediction).float().requires_grad_(True)\n",
    "\n",
    "    # Define target Betti numbers (e.g., 1 connected component, 0 holes).\n",
    "    target_betti = {0: 1, 1: 0}\n",
    "\n",
    "    # Initialize the persistent homology loss module.\n",
    "    topo_loss_fn = ll.PersistentHomologyLoss(target_betti, threshold=0.75)\n",
    "\n",
    "    # Compute the loss using the prediction tensor.\n",
    "    loss = topo_loss_fn(p_tensor)\n",
    "    print(\"Topological Loss:\", loss.item())\n",
    "    print(\"grad_fn:\", loss.grad_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "gt_path = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "save_base_path = \"./topo_cont_plots/\"\n",
    "\n",
    "test_paths = [gt_path] + [\"./comps/comp7.png\", \"./comps/comp9.png\", \"./comps/comp13.png\"] # + [f\"./lines/lines{i}.png\" for i in range(1, 3)]\n",
    "alph = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n",
    "\n",
    "t = 0.75\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(1, 4, figsize=(14, 4.5))\n",
    "fig.suptitle(f\"Topological Loss for Different Predictions (Threshold = {t})\", fontsize=20)\n",
    "\n",
    "# Define target Betti numbers\n",
    "target_betti = {0: 1, 1: 0}\n",
    "topo_loss_fn = ll.PersistentHomologyLoss(target_betti, threshold=t)\n",
    "\n",
    "# Process each image\n",
    "for i, test_path in enumerate(test_paths):\n",
    "    # Load and preprocess image\n",
    "    prediction = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "    #prediction_blur = cv2.GaussianBlur(prediction, (5, 5), 0)\n",
    "    #prediction_norm = prediction / 255.0\n",
    "    p_tensor = torch.from_numpy(prediction).float().requires_grad_(True)\n",
    "    \n",
    "    # Calculate topological loss\n",
    "    loss = topo_loss_fn(p_tensor)\n",
    "    \n",
    "    # Plot in the right subplot position\n",
    "    #row, col = i // 4, i % 4\n",
    "    axs[i].imshow(prediction, cmap='gray')\n",
    "    axs[i].set_title(f'({alph[i]}) Loss: {loss.item():.4f}', fontsize=16)\n",
    "    axs[i].axis('off')\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "fig.savefig(f\"{save_base_path}topo_loss_plots_report2.png\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ee = 2\n",
    "\n",
    "test_path = \"./comps/comp7.png\"\n",
    "prediction = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "p_tensor = torch.from_numpy(prediction).float().requires_grad_(True)\n",
    "\n",
    "endpoints_loss_fn = ll.EndpointsLoss(target_ee)\n",
    "\n",
    "loss = endpoints_loss_fn(p_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "importlib.reload(ll)\n",
    "importlib.reload(dl)\n",
    "\n",
    "gt_path = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "save_base_path = \"./topo_bran_plots/\"\n",
    "\n",
    "test_paths = [gt_path] + [\"./comps/comp8.png\", \"./comps/comp7.png\", \"./comps/comp10.png\", \"./comps/comp1.png\"] \n",
    "alph = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(5, 4, figsize=(16, 20))\n",
    "\n",
    "a = 50.0\n",
    "t = 0.8\n",
    "branching_fn = ll.EndpointsLoss(target_ee, alpha=a, threshold=t)\n",
    "\n",
    "slopes = [30, 40, 50, 60, 70]\n",
    "ts = [0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "gt_path = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "test_path = \"./comps/comp7.png\"\n",
    "prediction = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "p_tensor = torch.from_numpy(prediction).float().requires_grad_(True)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "for i in range(0, 5):\n",
    "    for j in range(0, 4):\n",
    "        branching_fn = ll.EndpointsLoss(target_ee, alpha=slopes[i], threshold=ts[j])\n",
    "        loss = branching_fn(p_tensor)\n",
    "        axs[i, j].imshow(prediction, cmap='gray')\n",
    "        #axs[i, j].set_title(f\"Loss: {loss.item():.1f}\", fontsize=16)\n",
    "        legend_elements = [Line2D([0], [0], marker='o', color='w', alpha=0.0, linewidth=0.0, label=f\"Alpha: {slopes[i]}\"),\n",
    "                           Line2D([0], [0], marker='o', color='w', alpha=0.0, linewidth=0.0, label=f\"Threshold: {ts[j]}\"),\n",
    "                           Line2D([0], [0], marker='o', color='w', alpha=0.0, linewidth=0.0, label=f\"Loss: {loss.item():.1f}\")\n",
    "                           ]\n",
    "        axs[i, j].legend(handles=legend_elements, prop={'size': 14}, loc='upper right')\n",
    "        axs[i, j].axis('off')\n",
    "        \n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{save_base_path}branching_loss_plots_appendix.png\", transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "gt_path = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "save_base_path = \"./topo_bran_plots/\"\n",
    "\n",
    "test_paths = [gt_path] + [\"./comps/comp7.png\", \"./comps/comp8.png\", \"./comps/comp11.png\"] # + [f\"./lines/lines{i}.png\" for i in range(1, 3)]\n",
    "alph = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n",
    "\n",
    "t = 0.85\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(1, 4, figsize=(14, 4.5))\n",
    "\n",
    "branching_fn = ll.EndpointsLoss(target_ee)\n",
    "\n",
    "# Process each image\n",
    "for i, test_path in enumerate(test_paths):\n",
    "    # Load and preprocess image\n",
    "    prediction = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "    #prediction_blur = cv2.GaussianBlur(prediction, (5, 5), 0)\n",
    "    #prediction_norm = prediction / 255.0\n",
    "    p_tensor = torch.from_numpy(prediction).float().requires_grad_(True)\n",
    "    \n",
    "    # Calculate topological loss\n",
    "    loss = branching_fn(p_tensor)\n",
    "    \n",
    "    # Plot in the right subplot position\n",
    "    #row, col = i // 4, i % 4\n",
    "    axs[i].imshow(prediction, cmap='gray')\n",
    "    axs[i].set_title(f'({alph[i]}) Loss: {loss.item():.4f}', fontsize=16)\n",
    "    axs[i].axis('off')\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "#fig.savefig(f\"{save_base_path}branch_loss_plots_report.png\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entry and Exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet34(weights=\"DEFAULT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "gt_cmap = \"./intersection_001/paths/path_1/cold_map.png\"\n",
    "test_path = \"./comps/comp8.png\"\n",
    "\n",
    "lc = ll.CmapLoss(1/1000)\n",
    "\n",
    "cmap_gt = cv2.imread(gt_cmap, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "path = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "_, binary = cv2.threshold(path, 1, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "cmap2 = torch.from_numpy(cmap).float().requires_grad_(True)\n",
    "cmap_f = torch.flatten(cmap2)\n",
    "\n",
    "path_np = np.array(path)\n",
    "path_t = torch.from_numpy(path_np).float().requires_grad_(True)\n",
    "path_f = torch.flatten(path_t)\n",
    "\n",
    "\n",
    "L_cmap = lc(cmap_f, path_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"./intersection_001/paths/path_1/path_line.png\"\n",
    "gt_cmap = \"./intersection_001/paths/path_1/cold_map.png\"\n",
    "test_path = \"./comps/comp1.png\"\n",
    "\n",
    "lb = ll.BCELoss()\n",
    "\n",
    "ground_truth_img = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "prediction_img = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "ground_truth = ground_truth_img / 255.0\n",
    "prediction = prediction_img / 255.0\n",
    "\n",
    "gt_tensor = torch.from_numpy(ground_truth).float()\n",
    "p_tensor = torch.from_numpy(prediction).float().requires_grad_(True)\n",
    "\n",
    "\n",
    "L_bce = lb(gt_tensor, p_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_bce"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".msc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
